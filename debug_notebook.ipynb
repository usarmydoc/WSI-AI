{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fb6b72",
   "metadata": {},
   "source": [
    "# WSI AI System - Development and Debugging Notebook\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "This notebook provides a comprehensive development and debugging environment for the multi-tissue WSI damage scoring system. Perfect for iterative development based on expert feedback.\n",
    "\n",
    "## ‚ö†Ô∏è Important Notes\n",
    "\n",
    "**Research Framework Only**: This system uses synthetic data for testing and development. Not validated for clinical use.\n",
    "\n",
    "**Purpose**: For debugging after feedback from biomedical informatics professor specializing in AI/ML and biomedical images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4bd8e",
   "metadata": {},
   "source": [
    "## üìö Import Required Libraries\n",
    "\n",
    "Setting up all necessary libraries with proper error handling and fallback mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b26a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "# Configure logging for debugging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add src to path for local imports\n",
    "sys.path.append(str(Path('.').absolute() / 'src'))\n",
    "\n",
    "# Optional imports with fallbacks\n",
    "try:\n",
    "    import cv2\n",
    "    CV2_AVAILABLE = True\n",
    "    print(\"‚úÖ OpenCV available\")\n",
    "except ImportError:\n",
    "    CV2_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è OpenCV not available - using simplified generation\")\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    SEABORN_AVAILABLE = True\n",
    "    print(\"‚úÖ Seaborn available\")\n",
    "except ImportError:\n",
    "    SEABORN_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Seaborn not available - using matplotlib only\")\n",
    "\n",
    "# Import our modules\n",
    "try:\n",
    "    from models.cnn import build_model\n",
    "    from evaluate import debug_evaluate_model, debug_calculate_metrics\n",
    "    from data.synthetic_data import debug_synthetic_data_generation, generate_synthetic_patch, create_synthetic_wsi\n",
    "    from visualization import debug_visualize_results\n",
    "    print(\"‚úÖ All local modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Some local modules unavailable: {e}\")\n",
    "\n",
    "print(\"üß™ WSI AI Development Environment Ready\")\n",
    "print(f\"üìÅ Working Directory: {Path('.').absolute()}\")\n",
    "print(f\"üêç Python Path: {sys.executable}\")\n",
    "print(f\"üì¶ NumPy version: {np.__version__}\")\n",
    "print(f\"üìä Matplotlib version: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbd43e",
   "metadata": {},
   "source": [
    "## üß¨ Generate Synthetic Tissue Patches\n",
    "\n",
    "Testing the synthetic tissue patch generation with different parameters and tissue types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test synthetic patch generation for different tissue types\n",
    "print(\"üß™ Testing Synthetic Patch Generation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tissue_types = [\"lung\", \"kidney\", \"heart\", \"liver\", \"bowel\"]\n",
    "damage_levels = [0, 3, 6, 9]  # Test different damage levels\n",
    "\n",
    "# Generate test patches for each combination\n",
    "test_patches = {}\n",
    "generation_times = {}\n",
    "\n",
    "for tissue in tissue_types:\n",
    "    test_patches[tissue] = {}\n",
    "    generation_times[tissue] = {}\n",
    "    \n",
    "    for damage in damage_levels:\n",
    "        print(f\"üî¨ Generating {tissue} patch with damage level {damage}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            patch = generate_synthetic_patch(\n",
    "                size=(224, 224, 3),\n",
    "                tissue_type=tissue,\n",
    "                damage_level=damage\n",
    "            )\n",
    "            generation_time = time.time() - start_time\n",
    "            \n",
    "            test_patches[tissue][damage] = patch\n",
    "            generation_times[tissue][damage] = generation_time\n",
    "            \n",
    "            print(f\"  ‚úÖ Success: {patch.shape}, {patch.dtype}, range: {patch.min()}-{patch.max()}\")\n",
    "            print(f\"  ‚è±Ô∏è Time: {generation_time:.3f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Failed: {e}\")\n",
    "            generation_times[tissue][damage] = None\n",
    "\n",
    "print(\"\\nüìä Generation Summary:\")\n",
    "for tissue in tissue_types:\n",
    "    valid_times = [t for t in generation_times[tissue].values() if t is not None]\n",
    "    if valid_times:\n",
    "        avg_time = np.mean(valid_times)\n",
    "        print(f\"  {tissue}: avg {avg_time:.3f}s per patch\")\n",
    "    else:\n",
    "        print(f\"  {tissue}: failed to generate patches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25fdb7",
   "metadata": {},
   "source": [
    "## üîç Debug Data Generation Process\n",
    "\n",
    "Comprehensive testing of the full data generation pipeline with detailed logging and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full data generation pipeline with various parameters\n",
    "print(\"üß™ Debug Data Generation Process\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different sample sizes and configurations\n",
    "test_configurations = [\n",
    "    {\"num_samples\": 8, \"tissues\": [\"lung\", \"kidney\"]},\n",
    "    {\"num_samples\": 16, \"tissues\": [\"lung\", \"kidney\", \"heart\", \"liver\", \"bowel\"]},\n",
    "    {\"num_samples\": 24, \"tissues\": None}  # Default configuration\n",
    "]\n",
    "\n",
    "generation_results = {}\n",
    "\n",
    "for i, config in enumerate(test_configurations):\n",
    "    print(f\"\\nüî¨ Configuration {i+1}: {config}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    memory_before = sys.getsizeof(generation_results)\n",
    "    \n",
    "    try:\n",
    "        # Run debug data generation\n",
    "        synthetic_data, synthetic_labels, synthetic_tissues = debug_synthetic_data_generation(\n",
    "            num_samples=config[\"num_samples\"],\n",
    "            tissue_types=config[\"tissues\"]\n",
    "        )\n",
    "        \n",
    "        generation_time = time.time() - start_time\n",
    "        memory_after = sys.getsizeof(generation_results) + sys.getsizeof(synthetic_data)\n",
    "        memory_used = memory_after - memory_before\n",
    "        \n",
    "        # Store results\n",
    "        generation_results[f\"config_{i+1}\"] = {\n",
    "            \"data\": synthetic_data,\n",
    "            \"labels\": synthetic_labels,\n",
    "            \"tissues\": synthetic_tissues,\n",
    "            \"time\": generation_time,\n",
    "            \"memory\": memory_used,\n",
    "            \"config\": config\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Success!\")\n",
    "        print(f\"  üìè Data shape: {synthetic_data.shape}\")\n",
    "        print(f\"  üè∑Ô∏è Labels shape: {synthetic_labels.shape}\")\n",
    "        print(f\"  üß¨ Tissues shape: {synthetic_tissues.shape}\")\n",
    "        print(f\"  ‚è±Ô∏è Generation time: {generation_time:.3f}s\")\n",
    "        print(f\"  üíæ Memory used: ~{memory_used/1024:.1f} KB\")\n",
    "        print(f\"  üìä Damage range: {synthetic_labels.min()}-{synthetic_labels.max()}\")\n",
    "        print(f\"  üéØ Tissue distribution: {dict(zip(*np.unique(synthetic_tissues, return_counts=True)))}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nüìà Overall Performance Summary:\")\n",
    "print(f\"  Total configurations tested: {len(generation_results)}\")\n",
    "for config_name, results in generation_results.items():\n",
    "    samples = results[\"config\"][\"num_samples\"]\n",
    "    time_per_sample = results[\"time\"] / samples\n",
    "    print(f\"  {config_name}: {time_per_sample:.3f}s per sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f8ef6",
   "metadata": {},
   "source": [
    "## ‚úÖ Validate Synthetic Data Quality\n",
    "\n",
    "Comprehensive validation of generated data including statistical analysis and quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data quality validation\n",
    "print(\"üîç Validating Synthetic Data Quality\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use the best configuration from previous test\n",
    "if generation_results:\n",
    "    # Get the largest successful dataset\n",
    "    best_config = max(generation_results.values(), key=lambda x: x[\"data\"].shape[0])\n",
    "    data = best_config[\"data\"]\n",
    "    labels = best_config[\"labels\"]  \n",
    "    tissues = best_config[\"tissues\"]\n",
    "    \n",
    "    print(f\"üìä Analyzing dataset with {data.shape[0]} samples\")\n",
    "    \n",
    "    # 1. Shape and Type Validation\n",
    "    print(f\"\\n1Ô∏è‚É£ Shape and Type Validation:\")\n",
    "    print(f\"  Data shape: {data.shape} ‚úÖ\" if len(data.shape) == 4 else f\"  Data shape: {data.shape} ‚ùå\")\n",
    "    print(f\"  Data type: {data.dtype} ‚úÖ\" if data.dtype == np.uint8 else f\"  Data type: {data.dtype} ‚ö†Ô∏è\")\n",
    "    print(f\"  Labels shape: {labels.shape} ‚úÖ\" if len(labels.shape) == 1 else f\"  Labels shape: {labels.shape} ‚ùå\")\n",
    "    print(f\"  Tissues shape: {tissues.shape} ‚úÖ\" if len(tissues.shape) == 1 else f\"  Tissues shape: {tissues.shape} ‚ùå\")\n",
    "    \n",
    "    # 2. Value Range Validation\n",
    "    print(f\"\\n2Ô∏è‚É£ Value Range Validation:\")\n",
    "    print(f\"  Pixel values: {data.min()} to {data.max()} ‚úÖ\" if 0 <= data.min() <= data.max() <= 255 else \"‚ùå\")\n",
    "    print(f\"  Damage labels: {labels.min()} to {labels.max()} ‚úÖ\" if 0 <= labels.min() <= labels.max() <= 9 else \"‚ùå\")\n",
    "    \n",
    "    # 3. Statistical Distribution Analysis\n",
    "    print(f\"\\n3Ô∏è‚É£ Statistical Distribution Analysis:\")\n",
    "    \n",
    "    # Pixel intensity statistics\n",
    "    mean_intensity = np.mean(data)\n",
    "    std_intensity = np.std(data)\n",
    "    print(f\"  Mean pixel intensity: {mean_intensity:.2f}\")\n",
    "    print(f\"  Std pixel intensity: {std_intensity:.2f}\")\n",
    "    print(f\"  Intensity range per channel:\")\n",
    "    for i, channel in enumerate(['R', 'G', 'B']):\n",
    "        ch_min = data[:,:,:,i].min()\n",
    "        ch_max = data[:,:,:,i].max()\n",
    "        ch_mean = data[:,:,:,i].mean()\n",
    "        print(f\"    {channel}: {ch_min}-{ch_max} (Œº={ch_mean:.1f})\")\n",
    "    \n",
    "    # Label distribution\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"  Damage label distribution:\")\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        percentage = (count / len(labels)) * 100\n",
    "        print(f\"    Level {label}: {count} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Tissue distribution\n",
    "    unique_tissues, tissue_counts = np.unique(tissues, return_counts=True)\n",
    "    print(f\"  Tissue type distribution:\")\n",
    "    for tissue, count in zip(unique_tissues, tissue_counts):\n",
    "        percentage = (count / len(tissues)) * 100\n",
    "        print(f\"    {tissue}: {count} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 4. Quality Metrics\n",
    "    print(f\"\\n4Ô∏è‚É£ Quality Metrics:\")\n",
    "    \n",
    "    # Check for identical patches (should be rare)\n",
    "    flattened_data = data.reshape(data.shape[0], -1)\n",
    "    unique_patches = np.unique(flattened_data, axis=0)\n",
    "    uniqueness = len(unique_patches) / len(flattened_data)\n",
    "    print(f\"  Patch uniqueness: {uniqueness:.3f} ‚úÖ\" if uniqueness > 0.8 else f\"  Patch uniqueness: {uniqueness:.3f} ‚ö†Ô∏è\")\n",
    "    \n",
    "    # Check tissue-damage correlation\n",
    "    tissue_damage_corr = {}\n",
    "    for tissue in unique_tissues:\n",
    "        tissue_mask = tissues == tissue\n",
    "        tissue_damages = labels[tissue_mask]\n",
    "        if len(tissue_damages) > 1:\n",
    "            # Calculate mean damage for this tissue\n",
    "            mean_damage = np.mean(tissue_damages)\n",
    "            tissue_damage_corr[tissue] = mean_damage\n",
    "    \n",
    "    print(f\"  Tissue-damage relationships:\")\n",
    "    for tissue, mean_damage in tissue_damage_corr.items():\n",
    "        print(f\"    {tissue}: Œº damage = {mean_damage:.2f}\")\n",
    "    \n",
    "    # 5. Memory and Performance Metrics\n",
    "    print(f\"\\n5Ô∏è‚É£ Memory and Performance:\")\n",
    "    data_size_mb = data.nbytes / (1024 * 1024)\n",
    "    print(f\"  Dataset size: {data_size_mb:.2f} MB\")\n",
    "    print(f\"  Per sample: {data_size_mb / data.shape[0]:.3f} MB\")\n",
    "    \n",
    "    validation_passed = (\n",
    "        len(data.shape) == 4 and\n",
    "        data.dtype == np.uint8 and\n",
    "        0 <= data.min() <= data.max() <= 255 and\n",
    "        0 <= labels.min() <= labels.max() <= 9 and\n",
    "        uniqueness > 0.5\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüéØ Overall Validation: {'‚úÖ PASSED' if validation_passed else '‚ùå FAILED'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for validation. Run data generation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce557ff",
   "metadata": {},
   "source": [
    "## üé® Visualize Synthetic Samples\n",
    "\n",
    "Create comprehensive visualizations of generated synthetic tissue patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a167896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations of synthetic data\n",
    "print(\"üé® Creating Synthetic Data Visualizations\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if generation_results:\n",
    "    # Use the best dataset\n",
    "    best_config = max(generation_results.values(), key=lambda x: x[\"data\"].shape[0])\n",
    "    data = best_config[\"data\"]\n",
    "    labels = best_config[\"labels\"]\n",
    "    tissues = best_config[\"tissues\"]\n",
    "    \n",
    "    # 1. Sample Grid by Tissue and Damage\n",
    "    print(\"üìã Creating tissue-damage grid visualization...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 4, figsize=(16, 20))\n",
    "    fig.suptitle('Synthetic Tissue Patches: By Type and Damage Level', fontsize=16)\n",
    "    \n",
    "    tissue_types = [\"lung\", \"kidney\", \"heart\", \"liver\", \"bowel\"]\n",
    "    damage_levels = [0, 3, 6, 9]\n",
    "    \n",
    "    for i, tissue in enumerate(tissue_types):\n",
    "        for j, damage in enumerate(damage_levels):\n",
    "            ax = axes[i, j]\n",
    "            \n",
    "            # Find a sample with this tissue and damage level (or closest)\n",
    "            tissue_mask = tissues == tissue\n",
    "            if np.any(tissue_mask):\n",
    "                tissue_data = data[tissue_mask]\n",
    "                tissue_labels = labels[tissue_mask]\n",
    "                \n",
    "                # Find closest damage level\n",
    "                damage_diffs = np.abs(tissue_labels - damage)\n",
    "                closest_idx = np.argmin(damage_diffs)\n",
    "                actual_damage = tissue_labels[closest_idx]\n",
    "                \n",
    "                sample = tissue_data[closest_idx]\n",
    "                ax.imshow(sample)\n",
    "                ax.set_title(f'{tissue.title()}\\nDamage: {actual_damage}', fontsize=10)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'No Sample', ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f'{tissue.title()}\\nDamage: {damage}', fontsize=10)\n",
    "            \n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. RGB Channel Analysis Visualization\n",
    "    print(\"üåà Creating RGB channel analysis...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('RGB Channel Analysis of Synthetic Data', fontsize=16)\n",
    "    \n",
    "    # Calculate channel statistics\n",
    "    r_channel = data[:,:,:,0]\n",
    "    g_channel = data[:,:,:,1]\n",
    "    b_channel = data[:,:,:,2]\n",
    "    \n",
    "    channels = [r_channel, g_channel, b_channel]\n",
    "    channel_names = ['Red', 'Green', 'Blue']\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    \n",
    "    # Top row: Histograms\n",
    "    for i, (channel, name, color) in enumerate(zip(channels, channel_names, colors)):\n",
    "        ax = axes[0, i]\n",
    "        ax.hist(channel.flatten(), bins=50, alpha=0.7, color=color, density=True)\n",
    "        ax.set_title(f'{name} Channel Distribution')\n",
    "        ax.set_xlabel('Pixel Value')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bottom row: Sample patches showing each channel\n",
    "    sample_idx = 0\n",
    "    sample_patch = data[sample_idx]\n",
    "    \n",
    "    for i, (name, color) in enumerate(zip(channel_names, colors)):\n",
    "        ax = axes[1, i]\n",
    "        channel_patch = np.zeros_like(sample_patch)\n",
    "        channel_patch[:,:,i] = sample_patch[:,:,i]\n",
    "        ax.imshow(channel_patch)\n",
    "        ax.set_title(f'{name} Channel Only')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Damage Level Progression Visualization\n",
    "    print(\"üìà Creating damage progression visualization...\")\n",
    "    \n",
    "    # For each tissue type, show damage progression\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(20, 25))\n",
    "    fig.suptitle('Damage Progression by Tissue Type', fontsize=16)\n",
    "    \n",
    "    for i, tissue in enumerate(tissue_types):\n",
    "        tissue_mask = tissues == tissue\n",
    "        if np.any(tissue_mask):\n",
    "            tissue_data = data[tissue_mask]\n",
    "            tissue_labels = labels[tissue_mask]\n",
    "            \n",
    "            # Sort by damage level\n",
    "            sort_indices = np.argsort(tissue_labels)\n",
    "            sorted_data = tissue_data[sort_indices]\n",
    "            sorted_labels = tissue_labels[sort_indices]\n",
    "            \n",
    "            # Show up to 10 samples in progression\n",
    "            n_samples = min(10, len(sorted_data))\n",
    "            sample_indices = np.linspace(0, len(sorted_data)-1, n_samples, dtype=int)\n",
    "            \n",
    "            # Create subplot for this tissue\n",
    "            tissue_fig, tissue_axes = plt.subplots(1, n_samples, figsize=(20, 4))\n",
    "            if n_samples == 1:\n",
    "                tissue_axes = [tissue_axes]\n",
    "                \n",
    "            for j, idx in enumerate(sample_indices):\n",
    "                tissue_axes[j].imshow(sorted_data[idx])\n",
    "                tissue_axes[j].set_title(f'Damage: {sorted_labels[idx]}', fontsize=10)\n",
    "                tissue_axes[j].axis('off')\n",
    "            \n",
    "            tissue_fig.suptitle(f'{tissue.title()} Damage Progression', fontsize=14)\n",
    "            plt.show()\n",
    "    \n",
    "    print(\"‚úÖ All visualizations completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization. Run data generation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6530e8",
   "metadata": {},
   "source": [
    "## üî¨ Analyze Tissue-Specific Patterns\n",
    "\n",
    "Deep analysis of tissue-specific characteristics and color patterns in synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ad84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of tissue-specific patterns and characteristics\n",
    "print(\"üî¨ Analyzing Tissue-Specific Patterns\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if generation_results:\n",
    "    best_config = max(generation_results.values(), key=lambda x: x[\"data\"].shape[0])\n",
    "    data = best_config[\"data\"]\n",
    "    labels = best_config[\"labels\"]\n",
    "    tissues = best_config[\"tissues\"]\n",
    "    \n",
    "    tissue_types = np.unique(tissues)\n",
    "    tissue_analysis = {}\n",
    "    \n",
    "    print(\"üìä Computing tissue-specific statistics...\")\n",
    "    \n",
    "    for tissue in tissue_types:\n",
    "        print(f\"\\nüß¨ Analyzing {tissue} tissue:\")\n",
    "        \n",
    "        # Get all samples for this tissue type\n",
    "        tissue_mask = tissues == tissue\n",
    "        tissue_data = data[tissue_mask]\n",
    "        tissue_labels = labels[tissue_mask]\n",
    "        \n",
    "        if len(tissue_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        analysis = {}\n",
    "        \n",
    "        # 1. Color Statistics\n",
    "        mean_rgb = np.mean(tissue_data, axis=(1, 2))  # Average RGB per sample\n",
    "        overall_rgb = np.mean(mean_rgb, axis=0)        # Overall average for tissue\n",
    "        std_rgb = np.std(mean_rgb, axis=0)             # Variability\n",
    "        \n",
    "        analysis['color_stats'] = {\n",
    "            'mean_rgb': overall_rgb,\n",
    "            'std_rgb': std_rgb,\n",
    "            'rgb_range': [mean_rgb.min(axis=0), mean_rgb.max(axis=0)]\n",
    "        }\n",
    "        \n",
    "        print(f\"  üé® Color characteristics:\")\n",
    "        print(f\"    Mean RGB: [{overall_rgb[0]:.1f}, {overall_rgb[1]:.1f}, {overall_rgb[2]:.1f}]\")\n",
    "        print(f\"    RGB Std:  [{std_rgb[0]:.1f}, {std_rgb[1]:.1f}, {std_rgb[2]:.1f}]\")\n",
    "        \n",
    "        # 2. Texture Analysis (basic)\n",
    "        # Calculate local standard deviation as a texture measure\n",
    "        texture_measures = []\n",
    "        for sample in tissue_data:\n",
    "            # Convert to grayscale for texture analysis\n",
    "            gray_sample = np.mean(sample, axis=2)\n",
    "            # Calculate local standard deviation (simple texture measure)\n",
    "            from scipy import ndimage\n",
    "            texture = ndimage.generic_filter(gray_sample, np.std, size=5)\n",
    "            texture_measures.append(np.mean(texture))\n",
    "        \n",
    "        analysis['texture_stats'] = {\n",
    "            'mean_texture': np.mean(texture_measures),\n",
    "            'std_texture': np.std(texture_measures)\n",
    "        }\n",
    "        \n",
    "        print(f\"  üåä Texture characteristics:\")\n",
    "        print(f\"    Mean texture: {np.mean(texture_measures):.2f}\")\n",
    "        print(f\"    Texture variability: {np.std(texture_measures):.2f}\")\n",
    "        \n",
    "        # 3. Damage Distribution for this tissue\n",
    "        damage_dist = np.bincount(tissue_labels, minlength=10)\n",
    "        analysis['damage_distribution'] = damage_dist\n",
    "        \n",
    "        print(f\"  üí• Damage distribution:\")\n",
    "        for damage_level, count in enumerate(damage_dist):\n",
    "            if count > 0:\n",
    "                print(f\"    Level {damage_level}: {count} samples\")\n",
    "        \n",
    "        # 4. Intensity-Damage Correlation\n",
    "        intensities = np.mean(tissue_data, axis=(1, 2, 3))\n",
    "        if len(intensities) > 1:\n",
    "            correlation = np.corrcoef(tissue_labels, intensities)[0, 1]\n",
    "            analysis['damage_intensity_correlation'] = correlation\n",
    "            print(f\"  üìà Damage-intensity correlation: {correlation:.3f}\")\n",
    "        \n",
    "        tissue_analysis[tissue] = analysis\n",
    "    \n",
    "    # Cross-tissue comparison\n",
    "    print(f\"\\nüîÑ Cross-Tissue Comparison:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Compare mean colors\n",
    "    print(\"üé® Mean RGB values by tissue:\")\n",
    "    for tissue in tissue_types:\n",
    "        if tissue in tissue_analysis:\n",
    "            rgb = tissue_analysis[tissue]['color_stats']['mean_rgb']\n",
    "            print(f\"  {tissue:>8}: [{rgb[0]:6.1f}, {rgb[1]:6.1f}, {rgb[2]:6.1f}]\")\n",
    "    \n",
    "    # Compare texture measures\n",
    "    print(\"\\nüåä Texture complexity by tissue:\")\n",
    "    for tissue in tissue_types:\n",
    "        if tissue in tissue_analysis:\n",
    "            texture = tissue_analysis[tissue]['texture_stats']['mean_texture']\n",
    "            print(f\"  {tissue:>8}: {texture:6.2f}\")\n",
    "    \n",
    "    # Compare damage-intensity correlations\n",
    "    print(\"\\nüìà Damage-intensity correlations:\")\n",
    "    for tissue in tissue_types:\n",
    "        if tissue in tissue_analysis and 'damage_intensity_correlation' in tissue_analysis[tissue]:\n",
    "            corr = tissue_analysis[tissue]['damage_intensity_correlation']\n",
    "            print(f\"  {tissue:>8}: {corr:6.3f}\")\n",
    "    \n",
    "    # Tissue separability analysis\n",
    "    print(f\"\\nüéØ Tissue Separability Analysis:\")\n",
    "    all_tissue_colors = []\n",
    "    all_tissue_labels = []\n",
    "    \n",
    "    for tissue in tissue_types:\n",
    "        if tissue in tissue_analysis:\n",
    "            tissue_mask = tissues == tissue\n",
    "            tissue_data = data[tissue_mask]\n",
    "            tissue_colors = np.mean(tissue_data, axis=(1, 2))\n",
    "            \n",
    "            all_tissue_colors.extend(tissue_colors)\n",
    "            all_tissue_labels.extend([tissue] * len(tissue_colors))\n",
    "    \n",
    "    # Calculate inter-tissue distances (simplified)\n",
    "    tissue_centers = {}\n",
    "    for tissue in tissue_types:\n",
    "        if tissue in tissue_analysis:\n",
    "            tissue_centers[tissue] = tissue_analysis[tissue]['color_stats']['mean_rgb']\n",
    "    \n",
    "    print(\"  RGB-based tissue separability:\")\n",
    "    for i, tissue1 in enumerate(tissue_types):\n",
    "        if tissue1 not in tissue_centers:\n",
    "            continue\n",
    "        for tissue2 in tissue_types[i+1:]:\n",
    "            if tissue2 not in tissue_centers:\n",
    "                continue\n",
    "            \n",
    "            # Euclidean distance in RGB space\n",
    "            dist = np.linalg.norm(tissue_centers[tissue1] - tissue_centers[tissue2])\n",
    "            print(f\"    {tissue1}-{tissue2}: {dist:.2f}\")\n",
    "    \n",
    "    print(\"‚úÖ Tissue-specific analysis completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for analysis. Run data generation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea58c9f",
   "metadata": {},
   "source": [
    "## üéì Professor Feedback Implementation Area\n",
    "\n",
    "This section is reserved for implementing specific recommendations from the biomedical informatics professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce244336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for implementing professor's feedback and recommendations\n",
    "print(\"üéì Professor Feedback Implementation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Document feedback here:\n",
    "professor_feedback = {\n",
    "    \"date\": \"YYYY-MM-DD\",\n",
    "    \"professor\": \"Assistant Professor Name\",\n",
    "    \"department\": \"Biomedical Informatics\",\n",
    "    \"specialization\": \"AI/ML for Biomedical Images\",\n",
    "    \"recommendations\": [\n",
    "        # Add specific recommendations here after meeting\n",
    "        # Example:\n",
    "        # \"Improve tissue color realism using histological reference data\",\n",
    "        # \"Add more sophisticated damage patterns based on pathology literature\",\n",
    "        # \"Implement proper validation metrics for synthetic data quality\"\n",
    "    ],\n",
    "    \"priority_changes\": [\n",
    "        # High priority items to implement first\n",
    "    ],\n",
    "    \"research_directions\": [\n",
    "        # Suggested future research directions\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üìù Feedback Summary:\")\n",
    "print(f\"  Date: {professor_feedback['date']}\")\n",
    "print(f\"  Professor: {professor_feedback['professor']}\")\n",
    "print(f\"  Department: {professor_feedback['department']}\")\n",
    "print(f\"  Specialization: {professor_feedback['specialization']}\")\n",
    "\n",
    "if professor_feedback['recommendations']:\n",
    "    print(\"\\nüí° Recommendations:\")\n",
    "    for i, rec in enumerate(professor_feedback['recommendations'], 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "else:\n",
    "    print(\"\\nüí° Recommendations: [To be added after professor meeting]\")\n",
    "\n",
    "# Implementation tracking\n",
    "implementation_status = {\n",
    "    # Track progress on each recommendation\n",
    "    # Example:\n",
    "    # \"recommendation_1\": {\"status\": \"in_progress\", \"completion\": 50, \"notes\": \"Working on color improvements\"},\n",
    "    # \"recommendation_2\": {\"status\": \"planned\", \"completion\": 0, \"notes\": \"Scheduled for next week\"}\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Implementation Status:\")\n",
    "if implementation_status:\n",
    "    for rec_id, status in implementation_status.items():\n",
    "        print(f\"  {rec_id}: {status['status']} ({status['completion']}% complete)\")\n",
    "        if status['notes']:\n",
    "            print(f\"    Notes: {status['notes']}\")\n",
    "else:\n",
    "    print(\"  [No implementations started yet]\")\n",
    "\n",
    "# Reserved space for implementing specific changes\n",
    "print(\"\\nüîß Implementation Space:\")\n",
    "print(\"  Use the cells below to implement specific feedback items\")\n",
    "\n",
    "# TODO: After getting feedback, implement specific recommendations here\n",
    "def implement_recommendation_1():\n",
    "    \"\"\"Template for implementing first recommendation.\"\"\"\n",
    "    print(\"üöß Implementing recommendation 1...\")\n",
    "    # Implementation code goes here\n",
    "    pass\n",
    "\n",
    "def implement_recommendation_2():\n",
    "    \"\"\"Template for implementing second recommendation.\"\"\"\n",
    "    print(\"üöß Implementing recommendation 2...\")\n",
    "    # Implementation code goes here\n",
    "    pass\n",
    "\n",
    "def run_validation_test():\n",
    "    \"\"\"Template for validation testing after implementing changes.\"\"\"\n",
    "    print(\"üß™ Running validation tests...\")\n",
    "    # Validation code goes here\n",
    "    pass\n",
    "\n",
    "# Uncomment and modify after getting feedback:\n",
    "# implement_recommendation_1()\n",
    "# implement_recommendation_2()\n",
    "# run_validation_test()\n",
    "\n",
    "print(\"‚úÖ Feedback implementation framework ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ec83a",
   "metadata": {},
   "source": [
    "## üìù Notes and Future Work\n",
    "\n",
    "Use this section to document findings, ideas, and future research directions based on development and professor feedback.\n",
    "\n",
    "### üéØ Pre-Meeting Preparation\n",
    "- [x] Repository ready with proper disclaimers\n",
    "- [x] Synthetic data generation functional\n",
    "- [x] Comprehensive debugging framework in place\n",
    "- [x] All \"medical-grade\" claims removed\n",
    "- [x] Professional documentation complete\n",
    "\n",
    "### üìã Post-Meeting Action Items\n",
    "- [ ] Implement specific architecture recommendations\n",
    "- [ ] Update synthetic data generation based on feedback\n",
    "- [ ] Add suggested validation approaches\n",
    "- [ ] Refine evaluation methodology\n",
    "- [ ] Update documentation\n",
    "\n",
    "### üî¨ Research Questions to Discuss\n",
    "1. What are the most important features for tissue damage assessment in real WSI data?\n",
    "2. How should we handle WSI preprocessing and patch extraction for optimal results?\n",
    "3. What validation approaches are most appropriate for real histopathological data?\n",
    "4. Are there specific architectural considerations for high-resolution WSI processing?\n",
    "5. What are the key clinical metrics we should focus on for pathologist validation?\n",
    "6. How can we ensure robust performance across different staining protocols and scanners?\n",
    "7. What data augmentation strategies work best for histopathological images?\n",
    "8. How should we handle class imbalance in real damage assessment datasets?\n",
    "\n",
    "### üí≠ Ideas and Observations\n",
    "*Use this space to document insights during development*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
